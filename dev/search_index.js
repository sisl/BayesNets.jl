var documenterSearchIndex = {"docs":
[{"location":"api/#API-Documentation","page":"API Documentation","title":"API Documentation","text":"","category":"section"},{"location":"api/","page":"API Documentation","title":"API Documentation","text":"Modules = [BayesNets, BayesNets.CPDs, BayesNets.CPDs.ProbabilisticGraphicalModels, BayesNets.Tables]","category":"page"},{"location":"api/#BayesNets.BDeuPrior","page":"API Documentation","title":"BayesNets.BDeuPrior","text":"Assigns equal scores to Markov equivalent structures\n\nα_ijk = x/{q_i * r_i} for each j, k and some given x\n\nsee DMU section 2.4.3\n\n\n\n\n\n","category":"type"},{"location":"api/#BayesNets.BayesNetSampler","page":"API Documentation","title":"BayesNets.BayesNetSampler","text":"Abstract type for sampling with:\n\nRandom.rand(BayesNet, BayesNetSampler)\nRandom.rand(BayesNet, BayesNetSampler, nsamples)\nRandom.rand!(Assignment, BayesNet, BayesNetSampler)\n\n\n\n\n\n","category":"type"},{"location":"api/#BayesNets.DirectSampler","page":"API Documentation","title":"BayesNets.DirectSampler","text":"Straightforward sampling from a BayesNet. The default sampler.\n\n\n\n\n\n","category":"type"},{"location":"api/#BayesNets.DirichletPrior","page":"API Documentation","title":"BayesNets.DirichletPrior","text":"Baysian Structure learning seeks to maximize P(G|D) In the Bayesian fashion, we can provide a prior over the parameters in our learning network. This is described using a Dirichlet Prior.\n\n\n\n\n\n","category":"type"},{"location":"api/#BayesNets.DiscreteBayesNet","page":"API Documentation","title":"BayesNets.DiscreteBayesNet","text":"DiscreteBayesNets are Bayesian Networks where every variable is an integer within 1:Nᵢ and every distribution is Categorical.\n\nThis representation is very common, and allows for the use of factors, for example in Probabilistic Graphical Models by Koller and Friedman\n\n\n\n\n\n","category":"type"},{"location":"api/#BayesNets.ExactInference","page":"API Documentation","title":"BayesNets.ExactInference","text":"Exact inference using factors and variable eliminations\n\n\n\n\n\n","category":"type"},{"location":"api/#BayesNets.Factor","page":"API Documentation","title":"BayesNets.Factor","text":"Factor(bn, name, evidence=Assignment())\n\nCreate a factor for a node, given some evidence.\n\n\n\n\n\n","category":"type"},{"location":"api/#BayesNets.Factor-2","page":"API Documentation","title":"BayesNets.Factor","text":"Factor(dims, potential)\n\nCreate a Factor corresponding to the potential.\n\n\n\n\n\n","category":"type"},{"location":"api/#BayesNets.Factor-Tuple{AbstractVector{Symbol}, Vector{Int64}, Nothing}","page":"API Documentation","title":"BayesNets.Factor","text":"Factor(dims, lengths, fill_value=0)\n\nCreate a factor with dimensions dims, each with lengths corresponding to lengths. fill_value will fill the potential array with that value. To keep uninitialized, use fill_value=nothing.\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.GibbsSampler","page":"API Documentation","title":"BayesNets.GibbsSampler","text":"The GibbsSampler type houses the parameters of the Gibbs sampling algorithm.  The parameters are defined below:\n\nburnin:  The first burnin samples will be discarded.  They will not be returned. The thinning parameter does not affect the burn in period. This is used to ensure that the Gibbs sampler converges to the target stationary distribution before actual samples are drawn.\n\nthinning: For every thinning + 1 number of samples drawn, only the last is kept. Thinning is used to reduce autocorrelation between samples. Thinning is not used during the burn in period. e.g. If thinning is 1, samples will be drawn in groups of two and only the second sample will be in the output.\n\ntimelimit: The number of milliseconds to run the algorithm. The algorithm will return the samples it has collected when either nsamples samples have been collected or timelimit milliseconds have passed.  If time_limit is null then the algorithm will run until nsamples have been collected. This means it is possible that zero samples are returned.\n\nerroriftimeout: If erroriftimeout is true and the timelimit expires, an error will be raised. If erroriftimeout is false and the time limit expires, the samples that have been collected so far will be returned.         This means it is possible that zero samples are returned.  Burn in samples will not be returned. If time_limit is null, this parameter does nothing.\n\nconsistent_with: the assignment that all samples must be consistent with (ie, Assignment(:A=>1) means all samples must have :A=1). Use to sample conditional distributions.\n\nmaxcachesize:  If null, cache as much as possible, otherwise cache at most \"maxcachesize\"  distributions\n\nvariableorder: variableorder determines the order of variables changed when generating a new sample. If null use a random order for every sample (this is different from updating the variables at random). Otherwise should be a list containing all the variables in the order they should be updated.\n\ninitial_sample:  The inital assignment to variables to use.  If null, the initial sample is chosen by briefly using a LikelihoodWeightedSampler.\n\n\n\n\n\n","category":"type"},{"location":"api/#BayesNets.GibbsSamplerState","page":"API Documentation","title":"BayesNets.GibbsSamplerState","text":"Used to cache various things the Gibbs sampler needs\n\n\n\n\n\n","category":"type"},{"location":"api/#BayesNets.GibbsSamplingFull","page":"API Documentation","title":"BayesNets.GibbsSamplingFull","text":"infer(im, inf)\n\nRun Gibbs sampling for N iterations. Each iteration changes all nodes. Discareds first burn_in samples and keeps only the thin-th sample. Ex, if thin=3, will discard the first two samples and keep the third.\n\n\n\n\n\n","category":"type"},{"location":"api/#BayesNets.GibbsSamplingNodewise","page":"API Documentation","title":"BayesNets.GibbsSamplingNodewise","text":"infer(GibbsSampling, state::Assignment, InferenceState)\n\nRun Gibbs sampling for N iterations. Each iteration changes one node.\n\nDiscareds first burn_in samples and keeps only the thin-th sample. Ex, if thin=3, will discard the first two samples and keep the third.\n\n\n\n\n\n","category":"type"},{"location":"api/#BayesNets.K2GraphSearch","page":"API Documentation","title":"BayesNets.K2GraphSearch","text":"K2GraphSearch\n\nA GraphSearchStrategy following the K2 algorithm. Takes polynomial time to find the optimal structure assuming a topological variable ordering.\n\n\n\n\n\n","category":"type"},{"location":"api/#BayesNets.LikelihoodWeightedSampler","page":"API Documentation","title":"BayesNets.LikelihoodWeightedSampler","text":"Likelihood Weighted Sampling\n\n\n\n\n\n","category":"type"},{"location":"api/#BayesNets.LikelihoodWeightingInference","page":"API Documentation","title":"BayesNets.LikelihoodWeightingInference","text":"Approximates p(query|evidence) with N weighted samples using likelihood weighted sampling\n\n\n\n\n\n","category":"type"},{"location":"api/#BayesNets.LoopyBelief","page":"API Documentation","title":"BayesNets.LoopyBelief","text":"Loopy belief propogation for a network.\n\nEarly stopping if change is messages < tol for `itersforconvergence' iterations. For no stopping, use tol < 0.\n\n\n\n\n\n","category":"type"},{"location":"api/#BayesNets.NegativeBayesianInformationCriterion","page":"API Documentation","title":"BayesNets.NegativeBayesianInformationCriterion","text":"NegativeBayesianInformationCriterion\n\nA ScoringFunction for the negative Bayesian information criterion.\n\nBIC = -2⋅L + k⋅ln(n)\n\n   L - the log likelihood of the data under the cpd\n   k - the number of free parameters to be estimated\n   n - the sample size\n\n\n\n\n\n","category":"type"},{"location":"api/#BayesNets.RejectionSampler","page":"API Documentation","title":"BayesNets.RejectionSampler","text":"Rejection Sampling in which the assignments are forced to be consistent with the provided values. Each sampler is attempted at most max_nsamples times before returning an empty assignment.\n\n\n\n\n\n","category":"type"},{"location":"api/#BayesNets.ScoreComponentCache","page":"API Documentation","title":"BayesNets.ScoreComponentCache","text":"ScoreComponentCache\n\nUsed to store scores in a priority queue such that graph search algorithms know when a particular construction has already been made.\n\n\n\n\n\n","category":"type"},{"location":"api/#BayesNets.ScoreComponentCache-Tuple{DataFrame}","page":"API Documentation","title":"BayesNets.ScoreComponentCache","text":"ScoreComponentCache(data::DataFrame)\n\nConstruct an empty ScoreComponentCache the size of ncol(data)\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.ScoringFunction","page":"API Documentation","title":"BayesNets.ScoringFunction","text":"ScoringFunction\n\nAn abstract type for which subtypes allow extracting CPD score components, which are to be maximized: score_component(::ScoringFunction, cpd::CPD, data::DataFrame)\n\n\n\n\n\n","category":"type"},{"location":"api/#BayesNets.UniformPrior","page":"API Documentation","title":"BayesNets.UniformPrior","text":"A uniform Dirichlet prior such that all α are the same\n\nDefaults to the popular K2 prior, α = 1, which is similar to Laplace Smoothing\n\nhttps://en.wikipedia.org/wiki/Additive_smoothing\n\n\n\n\n\n","category":"type"},{"location":"api/#Base.:*-Tuple{Table, Table}","page":"API Documentation","title":"Base.:*","text":"Table multiplication\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.Broadcast.broadcast!-Tuple{Any, Factor, Union{Symbol, AbstractVector{Symbol}}, Any}","page":"API Documentation","title":"Base.Broadcast.broadcast!","text":"broadcast!(f, ϕ, dims, values)\n\nBroadcast a vector (or array of vectors) across the dimension(s) dims Each vector in values will be broadcast acroos its respective dimension in dims\n\nSee Base.broadcast for more info.\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.Broadcast.broadcast-Tuple{Any, Factor, Union{Symbol, AbstractVector{Symbol}}, Any}","page":"API Documentation","title":"Base.Broadcast.broadcast","text":"broadcast(f, ϕ, dims, values)\n\nBroadcast a vector (or array of vectors) across the dimension(s) dims Each vector in values will be broadcast acroos its respective dimension in dims\n\nSee Base.broadcast for more info.\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.Sort.partialsort-Tuple{Table, Dict{Symbol, Any}}","page":"API Documentation","title":"Base.Sort.partialsort","text":"Given a Table, extract the rows which match the given assignment\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.convert-Tuple{Type{DataFrame}, Factor}","page":"API Documentation","title":"Base.convert","text":"Convert a Factor to a DataFrame\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.convert-Tuple{Type{Factor}, DiscreteCPD}","page":"API Documentation","title":"Base.convert","text":"convert(DiscreteCPD, cpd)\n\nConstruct a Factor from a DiscreteCPD.\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.count-Tuple{DiscreteBayesNet, Symbol, DataFrame}","page":"API Documentation","title":"Base.count","text":"Base.count(bn::BayesNet, name::NodeName, data::DataFrame)\n\nreturns a table containing all observed assignments and their corresponding counts\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.delete!-Tuple{BayesNet, Symbol}","page":"API Documentation","title":"Base.delete!","text":"delete!(bn::BayesNets, target::NodeName)\n\nRemoving cpds will alter the vertex indeces. In particular, removing the ith cpd will swap i and n and then remove n.\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.eltype-Tuple{Factor}","page":"API Documentation","title":"Base.eltype","text":"Returns Float64\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.getindex-Tuple{Factor, Dict{Symbol, Any}}","page":"API Documentation","title":"Base.getindex","text":"getindex(ϕ, a)\n\nGet values with dimensions consistent with an assignment. Colons select entire dimension.\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.in-Tuple{Symbol, Factor}","page":"API Documentation","title":"Base.in","text":"in(dim, ϕ) -> Bool\n\nReturn true if dim is in the Factor ϕ\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.indexin-Tuple{Symbol, Factor}","page":"API Documentation","title":"Base.indexin","text":"indexin(dims, ϕ)\n\nReturn the index of dimension dim in ϕ, or 0 if not in ϕ.\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.join","page":"API Documentation","title":"Base.join","text":"join(op, ϕ1, ϕ2, :outer, [v0])\njoin(op, ϕ1, ϕ2, :inner, [reducehow], [v0])\n\nPerforms either an inner or outer join,\n\nAn outer join returns a Factor with the union of the two dimensions The two factors are combined with Base.broadcast(op, ...)\n\nAn inner join keeps the dimensions in common between the two Factors. The extra dimensions are reduced with     reducedim(reducehow, ...) and then the two factors are combined with:     op(ϕ1[commondims].potential, ϕ2[commondims].potential)\n\n\n\n\n\n","category":"function"},{"location":"api/#Base.length-Tuple{Factor}","page":"API Documentation","title":"Base.length","text":"Total number of elements in Factor (potential)\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.names-Tuple{BayesNet}","page":"API Documentation","title":"Base.names","text":"Returns the ordered list of NodeNames\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.names-Tuple{Factor}","page":"API Documentation","title":"Base.names","text":"Names of each dimension\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.push!-Tuple{Factor, Symbol, Int64}","page":"API Documentation","title":"Base.push!","text":"Appends a new dimension to a Factor\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.rand-Tuple{BayesNet, BayesNetSampler, Integer}","page":"API Documentation","title":"Base.rand","text":"Generates a DataFrame containing a dataset of variable assignments. Always return a DataFrame with nsamples rows.\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.rand-Tuple{BayesNet, BayesNetSampler}","page":"API Documentation","title":"Base.rand","text":"Returns an assignment sampled from the bn using the provided sampler\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.rand-Tuple{BayesNet, GibbsSampler, Integer}","page":"API Documentation","title":"Base.rand","text":"Implements Gibbs sampling. (https://en.wikipedia.org/wiki/Gibbs_sampling) For finite variables, the posterior distribution is sampled by building the exact distribution. For continuous variables, the posterior distribution is sampled using Metropolis Hastings MCMC. Discrete variables with infinite support are currently not supported. The Gibbs Sampler only supports CPDs that return Univariate Distributions. (CPD{D<:UnivariateDistribution})\n\nSampling requires a GibbsSampler object which contains the parameters for Gibbs sampling. See the GibbsSampler documentation for parameter details.\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.similar-Tuple{Factor}","page":"API Documentation","title":"Base.similar","text":"similar(ϕ)\n\nReturn a factor similar to ϕ with unitialized values\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.size-Tuple{Factor}","page":"API Documentation","title":"Base.size","text":"size(ϕ, [dims...])\n\nReturns a tuple of the dimensions of ϕ\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.write-Tuple{IO, MIME{Symbol(\"text/plain\")}, DiscreteBayesNet}","page":"API Documentation","title":"Base.write","text":"write(io, text/plain, bn)\n\nWrites a text file containing the sufficient statistics for a discrete Bayesian network. This was inspired by the format listed in Appendix A of \"Correlated Encounter Model for Cooperative Aircraft in the National Airspace System Version 1.0\" by Mykel Kochenderfer.\n\nThe text file contains the following parameters:\n\nvariable labels: A space-delimited list specifies the variable labels, which are symbols.                  The ordering of the variables in this list determines the ordering of the variables                  in the other tables. Note that the ordering of the variable labels is not                  necessarily topological.\ngraphical structure: A binary matrix is used to represent the graphical structure of the Bayesian                  network. A 1 in the ith row and jth column means that there is a directed edge                  from the ith varible to the jth variable in the Bayesian network. The ordering                  of the variables are as defined in the variable labels section of the file.                  The entries are 0 or 1 and are not delimited.\nvariable instantiations: A list of integers specifying the number of instantiations for each variable.                  The list is space-delimited.\nsufficient statistics: A list of space-delimited integers Pₐⱼₖ  which specifies the sufficient statistics.                  The array is ordered first by increasing k, then increasing j, then increasing i.                  The variable ordering is defined in the variable labels section of the file.                  The list is a flattened matrices, where each matrix is rₐ × qₐ where rₐ is the number of                  instantiations of variable a and qₐ is the number of instantiations of the parents of                  variable a. The ordering is the same as the ordering of the distributions vector in                  the CategoricalCPD type.                  The entires in Pₐⱼₖ are floating point probability values.\n\nFor example, the network Success -> Forecast with Success ∈ [1, 2] and P(1) = 0.2, P(2) = 0.8 and Forecast ∈ [1, 2, 3] with     P(1 | 1) = 0.4, P(2 | 1) = 0.4, P(3 | 1) = 0.2     P(1 | 2) = 0.1, P(2 | 2) = 0.3, P(3 | 2) = 0.6\n\nIs output as:\n\nSuccess Forecast 01 00 2 3 2 4 4 1 3\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.CPDs.ProbabilisticGraphicalModels.infer-Union{Tuple{BN}, Tuple{LikelihoodWeightingInference, InferenceState{BN}}} where BN<:DiscreteBayesNet","page":"API Documentation","title":"BayesNets.CPDs.ProbabilisticGraphicalModels.infer","text":"Approximates p(query|evidence) with nsamples likelihood weighted samples.\n\nSince this uses a Factor, it is only efficient if the number of samples is (signifcantly) greater than the number of possible instantiations for the query variables\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.CPDs.ProbabilisticGraphicalModels.is_independent-Tuple{BayesNet, AbstractVector{Symbol}, AbstractVector{Symbol}, AbstractVector{Symbol}}","page":"API Documentation","title":"BayesNets.CPDs.ProbabilisticGraphicalModels.is_independent","text":"Returns whether the set of node names x is d-separated from the set y given the set given\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.CPDs.ProbabilisticGraphicalModels.markov_blanket-Tuple{BayesNet, Symbol}","page":"API Documentation","title":"BayesNets.CPDs.ProbabilisticGraphicalModels.markov_blanket","text":"Return the children, parents, and parents of children (excluding target) as a Set of NodeNames\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.CPDs.parents-Tuple{BayesNet, Symbol}","page":"API Documentation","title":"BayesNets.CPDs.parents","text":"Returns the parents as a list of NodeNames\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets._evidence_lambda-Tuple{Symbol, Dict{Symbol, Any}, Int64}","page":"API Documentation","title":"BayesNets._evidence_lambda","text":"Get the lambda-message to itself for an evidence node. If it isn't an evidence node, this will break\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets._get_parent_indeces-Tuple{AbstractVector{Symbol}, DataFrame}","page":"API Documentation","title":"BayesNets._get_parent_indeces","text":"score_component(a::ScoringFunction, cpd::CPD, data::DataFrame, cache::ScoreComponentCache)\n\nAs score_component(ScoringFunction, cpd, data), but returns pre-computed values from the cache if they exist, and populates the cache if they don't\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets._init_gibbs_sample","page":"API Documentation","title":"BayesNets._init_gibbs_sample","text":"_init_gibbs_sample(bn, evidence)\n\nA random sample of non-evidence nodes uniformly over their domain\n\n\n\n\n\n","category":"function"},{"location":"api/#BayesNets.bayesian_score","page":"API Documentation","title":"BayesNets.bayesian_score","text":"bayesian_score(G::DAG, names::Vector{Symbol}, data::DataFrame[, ncategories::Vector{Int}[, prior::DirichletPrior]])\n\nCompute the bayesian score for graph structure g, with the data in data. names containes a symbol corresponding to each vertex in g that is the name of a column in data. ncategories is a vector of the number of values that each variable in the Bayesian network can take.\n\nNote that every entry in data must be an integer greater than 0\n\n\n\n\n\n","category":"function"},{"location":"api/#BayesNets.bayesian_score_component-Union{Tuple{I}, Tuple{Int64, AbstractVector{I}, AbstractVector{Int64}, AbstractMatrix{Int64}, AbstractMatrix{Float64}}} where I<:Integer","page":"API Documentation","title":"BayesNets.bayesian_score_component","text":"Computes the Bayesian score component for the given target variable index and     Dirichlet prior counts given in alpha\n\nINPUT:     i       - index of the target variable     parents - list of indeces of parent variables (should not contain self)     r       - list of instantiation counts accessed by variable index               r[1] gives number of discrete states variable 1 can take on     data - matrix of sufficient statistics / counts               d[j,k] gives the number of times the target variable took on its kth instantiation               given the jth parental instantiation\n\nOUTPUT:     the Bayesian score, Float64\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.children-Tuple{BayesNet, Symbol}","page":"API Documentation","title":"BayesNets.children","text":"Returns the children as a list of NodeNames\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.duplicate-Tuple{Array, Tuple{Vararg{Int64, N}} where N}","page":"API Documentation","title":"BayesNets.duplicate","text":"duplicate(A, dims)\n\nRepeates an array only through higer dimensions dims.\n\nCustom version of repeate, but only outer repetition, and only duplicates the array for the number of times specified in dims for dimensions greater than ndims(A). If dims is empty, returns a copy of A.\n\njulia> duplicate(collect(1:3), (2,))\n3×2 Array{Int64,2}:\n 1  1\n 2  2\n 3  3\n\njulia> duplicate([1 3; 2 4], (3,))\n2×2×3 Array{Int64,3}:\n[:, :, 1] =\n 1  3\n 2  4\n\n[:, :, 2] =\n 1  3\n 2  4\n\n[:, :, 3] =\n 1  3\n 2  4\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.eval_mb_cpd-Tuple{Symbol, Int64, Dict{Symbol, Any}, Vector}","page":"API Documentation","title":"BayesNets.eval_mb_cpd","text":"eval_mb_cpd(node, ncategories, assignment, mb_cpds)\n\nReturn the potential of all instances of a node given its markove blanket as a WeightVec:     P(node | panode) * Prod (c in children) P(c | pac)\n\nTrys out all possible values of node (assumes categorical) Assignment should have values for all in the Markov blanket, including the variable itself.\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.get_asia_bn-Tuple{}","page":"API Documentation","title":"BayesNets.get_asia_bn","text":"An ergodic version of the asia network, with the E variable removed\n\nOrignal network: Lauritzen, Steffen L. and David J. Spiegelhalter, 1988\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.get_finite_distribution!-Tuple{BayesNets.GibbsSamplerState, Symbol, Dict{Symbol, Any}, AbstractArray}","page":"API Documentation","title":"BayesNets.get_finite_distribution!","text":"Helper to sampleposteriorfinite\n\nModifies a and gss\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.get_mb_cpds-Tuple{BayesNet, Symbol}","page":"API Documentation","title":"BayesNets.get_mb_cpds","text":"Get the cpd's of a node and its children\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.get_sat_fail_bn-Tuple{}","page":"API Documentation","title":"BayesNets.get_sat_fail_bn","text":"Satellite failure network from DMU, pg 17\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.get_sprinkler_bn-Tuple{}","page":"API Documentation","title":"BayesNets.get_sprinkler_bn","text":"The usual sprinkler problem\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.get_weighted_dataframe-Tuple{BayesNet, Integer, Dict{Symbol, Any}}","page":"API Documentation","title":"BayesNets.get_weighted_dataframe","text":"A dataset of variable assignments is obtained with an additional column of weights in accordance with the likelihood of each assignment.\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.get_weighted_sample!-Tuple{Dict{Symbol, Any}, BayesNet, Dict{Symbol, Any}}","page":"API Documentation","title":"BayesNets.get_weighted_sample!","text":"Draw an assignment from the Bayesian network but set any variables in the evidence accordingly. Returns the assignment and the probability weighting associated with the evidence.\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.gibbs_sample-Tuple{BayesNet, Integer, Integer}","page":"API Documentation","title":"BayesNets.gibbs_sample","text":"Implements Gibbs sampling. (https://en.wikipedia.org/wiki/Gibbs_sampling) For finite variables, the posterior distribution is sampled by building the exact distribution. For continuous variables, the posterior distribution is sampled using Metropolis Hastings MCMC. Discrete variables with infinite support are currently not supported. The Gibbs Sampler only supports CPDs that return Univariate Distributions. (CPD{D<:UnivariateDistribution})\n\nbn:: A Bayesian Network to sample from.  bn should only contain CPDs that return UnivariateDistributions.\n\nnsamples: The number of samples to return.\n\nburnin:  The first burnin samples will be discarded.  They will not be returned. The thinning parameter does not affect the burn in period. This is used to ensure that the Gibbs sampler converges to the target stationary distribution before actual samples are drawn.\n\nthinning: For every thinning + 1 number of samples drawn, only the last is kept. Thinning is used to reduce autocorrelation between samples. Thinning is not used during the burn in period. e.g. If thinning is 1, samples will be drawn in groups of two and only the second sample will be in the output.\n\ntimelimit: The number of milliseconds to run the algorithm. The algorithm will return the samples it has collected when either nsamples samples have been collected or timelimit milliseconds have passed.  If time_limit is null then the algorithm will run until nsamples have been collected. This means it is possible that zero samples are returned.\n\nerroriftimeout: If erroriftimeout is true and the timelimit expires, an error will be raised. If erroriftimeout is false and the time limit expires, the samples that have been collected so far will be returned. \tThis means it is possible that zero samples are returned.  Burn in samples will not be returned. If time_limit is null, this parameter does nothing.\n\nconsistent_with: the assignment that all samples must be consistent with (ie, Assignment(:A=>1) means all samples must have :A=1). Use to sample conditional distributions.\n\nmaxcachesize:  If null, cache as much as possible, otherwise cache at most \"maxcachesize\"  distributions\n\nvariableorder: variableorder determines the order of variables changed when generating a new sample. If null use a random order for every sample (this is different from updating the variables at random). Otherwise should be a list containing all the variables in the order they should be updated.\n\ninitialsample:  The inital assignment to variables to use.  If null, the initial sample is chosen by briefly running rand(bn, getweighted_dataframe).\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.gibbs_sample_main_loop-Tuple{BayesNets.GibbsSamplerState, Integer, Integer, Dict{Symbol, Any}, Dict{Symbol, Any}, Union{Nothing, Vector{Symbol}}, Union{Nothing, Int64}}","page":"API Documentation","title":"BayesNets.gibbs_sample_main_loop","text":"The main loop associated with Gibbs sampling Returns a data frame with nsamples samples\n\nSupports the various parameters supported by gibbssample Refer to gibbssample for parameter meanings\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.ndgrid_fill!-NTuple{4, Any}","page":"API Documentation","title":"BayesNets.ndgrid_fill!","text":"???\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.pattern-Tuple{Factor, Any}","page":"API Documentation","title":"BayesNets.pattern","text":"pattern(ϕ, [dims])\n\nReturn an array with the pattern of each dimension's state for all possible instances\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.rand_bn_inference","page":"API Documentation","title":"BayesNets.rand_bn_inference","text":"rand_bn_inference(bn, num_query=2, num_evidence=3)\n\nGenerate a random inference state for a Bayesian Network with an evidence assignment sample uniformly over the chosen nodes' domain.\n\n\n\n\n\n","category":"function"},{"location":"api/#BayesNets.rand_cpd","page":"API Documentation","title":"BayesNets.rand_cpd","text":"rand_cpd(bn::DiscreteBayesNet, ncategories::Int, target::NodeName, parents::NodeNames=NodeName[])\n\nReturn a CategoricalCPD with the given number of categories with random categorical distributions\n\n\n\n\n\n","category":"function"},{"location":"api/#BayesNets.rand_discrete_bn","page":"API Documentation","title":"BayesNets.rand_discrete_bn","text":"rand_discrete_bn(num_nodes16, max_num_parents=3,\n        max_num_states=5, connected=true)\n\nGenerate a random DiscreteBayesNet.\n\nCreates DiscreteBayesNet with num_nodes nodes, with each node having a random number of states and parents, up to max_num_parents and max_num_parents, respectively. If connected, each node (except the first) will be guaranteed at least one parent, making the graph connected.\n\n\n\n\n\n","category":"function"},{"location":"api/#BayesNets.readxdsl-Tuple{AbstractString}","page":"API Documentation","title":"BayesNets.readxdsl","text":"readxdsl( filename::AbstractString )\n\nReturn a DiscreteBayesNet read from the xdsl file\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.reducedim","page":"API Documentation","title":"BayesNets.reducedim","text":"reducedim(op, ϕ, dims, [v0])\n\nReduce dimensions dims in ϕ using function op.\n\n\n\n\n\n","category":"function"},{"location":"api/#BayesNets.sample_posterior!-Tuple{BayesNets.GibbsSamplerState, Symbol, Dict{Symbol, Any}}","page":"API Documentation","title":"BayesNets.sample_posterior!","text":"set a[varname] ~ P(varname | not varname)\n\nModifies a and caches in gss\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.sample_posterior_continuous!-Tuple{BayesNets.GibbsSamplerState, Symbol, Dict{Symbol, Any}, Distribution{Univariate, Continuous}}","page":"API Documentation","title":"BayesNets.sample_posterior_continuous!","text":"Implements Metropolis-Hastings with a normal distribution proposal with mean equal to the previous value of the variable \"varname\" and stddev equal to 10 times the standard deviation of the distribution of the target variable given its parents ( var_distribution should be get(bn, varname)(a) )\n\nMH will go through nsamples iterations.  If no proposal is accepted, the original value will remain\n\nThis function expects that a[varname] is within the support of the distribution, it will not check to make sure this is true\n\nHelper to sample_posterior Should only be used to sampling continuous distributions\n\nset a[varname] ~ P(varname | not varname)\n\nModifies a and caches in gss\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.sample_posterior_finite!-Tuple{BayesNets.GibbsSamplerState, Symbol, Dict{Symbol, Any}, AbstractArray}","page":"API Documentation","title":"BayesNets.sample_posterior_finite!","text":"Helper to sample_posterior Should only be called if the variable associated with varname is discrete\n\nset a[varname] ~ P(varname | not varname)\n\nModifies both a and gss\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.sample_weighted_dataframe!-Tuple{Dict{Symbol, Any}, DataFrame}","page":"API Documentation","title":"BayesNets.sample_weighted_dataframe!","text":"Chooses a sample at random from a weighted dataframe\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.score_component-Tuple{ScoringFunction, CPD, DataFrame}","page":"API Documentation","title":"BayesNets.score_component","text":"score_component(a::ScoringFunction, cpd::CPD, data::DataFrame)\n\nExtract a Float64 score for a cpd given the data. One seeks to maximize the score.\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.score_components-Union{Tuple{C}, Tuple{ScoringFunction, Vector{C}, DataFrame}} where C<:CPD","page":"API Documentation","title":"BayesNets.score_components","text":"score_components(a::ScoringFunction, cpd::CPD, data::DataFrame)\nscore_components(a::ScoringFunction, cpds::Vector{CPD}, data::DataFrame, cache::ScoreComponentCache)\n\nGet a list of score components for all cpds\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.statistics-Tuple{Int64, AbstractVector{Int64}, AbstractVector{Int64}, AbstractMatrix{Int64}}","page":"API Documentation","title":"BayesNets.statistics","text":"statistics(\n    targetind::Int,\n    parents::AbstractVector{Int},\n    ncategories::AbstractVector{Int},\n    data::AbstractMatrix{Int}\n    )\n\noutputs a sufficient statistics table for the target variable that is r × q where r = ncategories[i] is the number of variable instantiations and q is the number of parental instantiations of variable i\n\nThe r-values are ordered from 1 → ncategories[i] The q-values are ordered in the same ordering as ind2sub() in Julia Base     Thus the instantiation of the first parent (by order given in parents[i])     is varied the fastest.\n\nex:     Variable 1 has parents 2 and 3, with r₁ = 2, r₂ = 2, r₃ = 3     q for variable 1 is q = r₂×r₃ = 6     N will be a 6×2 matrix where:         N[1,1] is the number of time v₁ = 1, v₂ = 1, v₃ = 1         N[2,1] is the number of time v₁ = 1, v₂ = 2, v₃ = 1         N[3,1] is the number of time v₁ = 1, v₂ = 1, v₃ = 2         N[4,1] is the number of time v₁ = 1, v₂ = 2, v₃ = 2         N[5,1] is the number of time v₁ = 1, v₂ = 1, v₃ = 3         N[6,1] is the number of time v₁ = 1, v₂ = 2, v₃ = 3         N[6,2] is the number of time v₁ = 2, v₂ = 1, v₃ = 1         ...\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.statistics-Tuple{Vector{Vector{Int64}}, AbstractVector{Int64}, AbstractMatrix{Int64}}","page":"API Documentation","title":"BayesNets.statistics","text":"statistics(\n    parent_list::Vector{Vector{Int}},\n    ncategories::AbstractVector{Int},\n    data::AbstractMatrix{Int},\n    )\n\nComputes sufficient statistics from a discrete dataset for a Discrete Bayesian Net structure\n\nINPUT:     parents:         list of lists of parent indices         A variable with index i has ncategories[i]         and row in data[i,:]         No acyclicity checking is done     ncategories:         list of variable bin counts, or number of         discrete values the variable can take on, v ∈ {1 : ncategories[i]}     data:         table of discrete values [n×m]         where n is the number of nodes         and m is the number of samples\n\nOUTPUT:     N :: Vector{Matrix{Int}}         a sufficient statistics table for each variable         Variable with index i has statistics table N[i],         which is r × q where         r = ncategories[i] is the number of variable instantiations and         q is the number of parental instantiations of variable i\n\n    The r-values are ordered from 1 → ncategories[i]\n    The q-values are ordered in the same ordering as ind2sub() in Julia Base\n        Thus the instantiation of the first parent (by order given in parents[i])\n        is varied the fastest.\n\n    ex:\n        Variable 1 has parents 2 and 3, with r₁ = 2, r₂ = 2, r₃ = 3\n        q for variable 1 is q = r₂×r₃ = 6\n        N[1] will be a 6×2 matrix where:\n            N[1][1,1] is the number of time v₁ = 1, v₂ = 1, v₃ = 1\n            N[1][2,1] is the number of time v₁ = 1, v₂ = 2, v₃ = 1\n            N[1][3,1] is the number of time v₁ = 1, v₂ = 1, v₃ = 2\n            N[1][4,1] is the number of time v₁ = 1, v₂ = 2, v₃ = 2\n            N[1][5,1] is the number of time v₁ = 1, v₂ = 1, v₃ = 3\n            N[1][6,1] is the number of time v₁ = 1, v₂ = 2, v₃ = 3\n            N[1][6,2] is the number of time v₁ = 2, v₂ = 1, v₃ = 1\n            ...\n\nThis function uses sparse matrix black magic and was mercilessly stolen from Ed Schmerling.\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.sumout-Tuple{Table, Union{Symbol, AbstractVector{Symbol}}}","page":"API Documentation","title":"BayesNets.sumout","text":"sumout(t, v)\n\nTable marginalization\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.table-Tuple{DiscreteBayesNet, Symbol}","page":"API Documentation","title":"BayesNets.table","text":"table(bn::DiscreteBayesNet, name::NodeName)\n\nConstructs the CPD factor associated with the given node in the BayesNet\n\n\n\n\n\n","category":"method"},{"location":"api/#Distributions.logpdf-Tuple{BayesNet, Dict{Symbol, Any}}","page":"API Documentation","title":"Distributions.logpdf","text":"The logpdf of a given assignment after conditioning on the values\n\n\n\n\n\n","category":"method"},{"location":"api/#Distributions.ncategories-Tuple{DiscreteBayesNet, Symbol}","page":"API Documentation","title":"Distributions.ncategories","text":"Distributions.ncategories(bn::DiscreteBayesNet, node::Symbol)\n\nReturn the number of categories for a node in the network.\n\n\n\n\n\n","category":"method"},{"location":"api/#Distributions.pdf-Tuple{BayesNet, Dict{Symbol, Any}}","page":"API Documentation","title":"Distributions.pdf","text":"The pdf of a given assignment after conditioning on the values\n\n\n\n\n\n","category":"method"},{"location":"api/#Graphs.dst-Tuple{Pair{Int64, Int64}}","page":"API Documentation","title":"Graphs.dst","text":"Returns all descendants as a list of NodeNames.\n\n\n\n\n\n","category":"method"},{"location":"api/#Graphs.has_edge-Tuple{BayesNet, Symbol, Symbol}","page":"API Documentation","title":"Graphs.has_edge","text":"Whether the BayesNet contains the given edge\n\n\n\n\n\n","category":"method"},{"location":"api/#Graphs.neighbors-Tuple{BayesNet, Symbol}","page":"API Documentation","title":"Graphs.neighbors","text":"Returns all neighbors as a list of NodeNames.\n\n\n\n\n\n","category":"method"},{"location":"api/#LinearAlgebra.normalize!-Tuple{Factor, Union{Symbol, AbstractVector{Symbol}}}","page":"API Documentation","title":"LinearAlgebra.normalize!","text":"normalize!(ϕ, dims; p=1)\nnormalize!(ϕ; p=1)\n\nNormalize the factor so all instances of dims have (or the entire factors has) p-norm of 1\n\n\n\n\n\n","category":"method"},{"location":"api/#LinearAlgebra.normalize!-Tuple{Table}","page":"API Documentation","title":"LinearAlgebra.normalize!","text":"Table normalization Ensures that the :potential column sums to one\n\n\n\n\n\n","category":"method"},{"location":"api/#LinearAlgebra.normalize-Tuple{Factor, Vararg{Any}}","page":"API Documentation","title":"LinearAlgebra.normalize","text":"normalize!(ϕ, dims; p=1)\nnormalize!(ϕ; p=1)\n\nReturn a normalized copy of the factor so all instances of dims have (or the entire factors has) p-norm of 1\n\n\n\n\n\n","category":"method"},{"location":"api/#Random.rand!-Tuple{Dict{Symbol, Any}, BayesNet, BayesNetSampler}","page":"API Documentation","title":"Random.rand!","text":"Overwrites assignment with a sample from bn using the sampler\n\n\n\n\n\n","category":"method"},{"location":"api/#Random.rand!-Tuple{Dict{Symbol, Any}, BayesNet, GibbsSampler}","page":"API Documentation","title":"Random.rand!","text":"NOTE: this is inefficient. Use rand(bn, GibbsSampler, nsamples) whenever you can\n\n\n\n\n\n","category":"method"},{"location":"api/#Random.rand!-Tuple{Factor}","page":"API Documentation","title":"Random.rand!","text":"rand!(ϕ)\n\nFill with random values\n\n\n\n\n\n","category":"method"},{"location":"api/#StatsAPI.fit-Tuple{Type{Table}, DataFrame}","page":"API Documentation","title":"StatsAPI.fit","text":"takes a list of observations of assignments represented as a DataFrame or a set of data samples (without :potential), takes the unique assignments, and estimates the associated probability of each assignment based on its frequency of occurrence.\n\n\n\n\n\n","category":"method"},{"location":"api/#StatsAPI.fit-Union{Tuple{C}, Tuple{Type{BayesNet{C}}, DataFrame, GraphSearchStrategy}} where C<:CPD","page":"API Documentation","title":"StatsAPI.fit","text":"fit{C<:CPD}(::Type{BayesNet{C}}, ::DataFrame, ::GraphSearchStrategy)\n\nRun the graph search algorithm defined by GraphSearchStrategy\n\n\n\n\n\n","category":"method"},{"location":"api/#StatsAPI.fit-Union{Tuple{T}, Tuple{Type{BayesNet{T}}, DataFrame, Tuple{Vararg{Pair{Symbol, Symbol}}}}} where T<:CPD","page":"API Documentation","title":"StatsAPI.fit","text":"fit(::Type{BayesNet}, data, edges)\n\nFit a Bayesian Net whose variables are the columns in data and whose edges are given in edges\n\nex: fit(DiscreteBayesNet, data, (:A=>:B, :C=>B))\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.CPDs.CategoricalCPD","page":"API Documentation","title":"BayesNets.CPDs.CategoricalCPD","text":"A categorical distribution, P(x|parents(x)) where all parents are discrete integers 1:N.\n\nThe ordering of distributions array follows the convention in Decision Making Under Uncertainty. Suppose a variable has three discrete parents. The first parental instantiation assigns all parents to their first bin. The second will assign the first parent (as defined in parents) to its second bin and the other parents to their first bin. The sequence continues until all parents are instantiated to their last bins.\n\nThis is equivalent to:\n\nX,Y,Z 1,1,1 2,1,1 1,2,1 2,2,1 1,1,2 ...\n\n\n\n\n\n","category":"type"},{"location":"api/#BayesNets.CPDs.ConditionalLinearGaussianCPD","page":"API Documentation","title":"BayesNets.CPDs.ConditionalLinearGaussianCPD","text":"A conditional linear Gaussian CPD, always returns a Normal{Float64}\n\nThis is a combination of the CategoricalCPD and the LinearGaussianCPD.\nFor a variable with N discrete parents and M continuous parents, it will construct\na linear gaussian distribution for all M parents for each discrete instantiation.\n\n                  { Normal(μ=a₁×continuous_parents(x) + b₁, σ₁) for discrete instantiation 1\nP(x|parents(x)) = { Normal(μ=a₂×continuous_parents(x) + b₂, σ₂) for discrete instantiation 2\n                  { ...\n\n\n\n\n\n","category":"type"},{"location":"api/#BayesNets.CPDs.LinearGaussianCPD","page":"API Documentation","title":"BayesNets.CPDs.LinearGaussianCPD","text":"A linear Gaussian CPD, always returns a Normal\n\nAssumes that target and all parents can be converted to Float64 (ie, are numeric)\n\nP(x|parents(x)) = Normal(μ=a×parents(x) + b, σ)\n\n\n\n\n\n","category":"type"},{"location":"api/#BayesNets.CPDs.StaticCPD","page":"API Documentation","title":"BayesNets.CPDs.StaticCPD","text":"A CPD for which the distribution never changes.     target: name of the CPD's variable     parents: list of parent variables.     d: a Distributions.jl distribution\n\nWhile a StaticCPD can have parents, their assignments will not affect the distribution.\n\n\n\n\n\n","category":"type"},{"location":"api/#Base.get!-Tuple{Dict{Symbol, Any}, CPD, DataFrame, Int64}","page":"API Documentation","title":"Base.get!","text":"get!(a::Assignment, b::Assignment)\n\nModify and return the assignment to contain the ith entry\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.rand-Tuple{CPD, Dict{Symbol, Any}}","page":"API Documentation","title":"Base.rand","text":"rand(cpd::CPD)\n\nCondition and then draw from the distribution\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.CPDs.disttype-Union{Tuple{CPD{D}}, Tuple{D}} where D","page":"API Documentation","title":"BayesNets.CPDs.disttype","text":"disttype(cpd::CPD)\n\nReturn the type of the CPD's distribution\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.CPDs.infer_number_of_instantiations-Union{Tuple{AbstractVector{I}}, Tuple{I}} where I<:Int64","page":"API Documentation","title":"BayesNets.CPDs.infer_number_of_instantiations","text":"infer_number_of_instantiations{I<:Int}(arr::AbstractVector{I})\n\nInfer the number of instantiations, N, for a data type, assuming that it takes on the values 1:N\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.CPDs.name-Tuple{CPD}","page":"API Documentation","title":"BayesNets.CPDs.name","text":"name(cpd::CPD)\n\nReturn the NodeName for the variable this CPD is defined for.\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.CPDs.nparams-Tuple{CPD}","page":"API Documentation","title":"BayesNets.CPDs.nparams","text":"nparams(cpd::CPD)\n\nReturn the number of free parameters that needed to be estimated for the CPD\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.CPDs.parentless-Tuple{CPD}","page":"API Documentation","title":"BayesNets.CPDs.parentless","text":"parentless(cpd::CPD)\n\nReturn whether this CPD has parents.\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.CPDs.parents-Tuple{CPD}","page":"API Documentation","title":"BayesNets.CPDs.parents","text":"parents(cpd::CPD)\n\nReturn the parents for this CPD as a vector of NodeName.\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.CPDs.strip_arg-Tuple{Symbol}","page":"API Documentation","title":"BayesNets.CPDs.strip_arg","text":"strip_arg(arg::Symbol)\n\nStrip anything extra (type annotations, default values, etc) from an argument. For now this cannot handle keyword arguments (it will throw an error).\n\n\n\n\n\n","category":"method"},{"location":"api/#Distributions.logpdf-Tuple{CPD, DataFrame}","page":"API Documentation","title":"Distributions.logpdf","text":"logpdf(cpd::CPD, data::DataFrame)\n\nReturn the logpdf across the dataset\n\n\n\n\n\n","category":"method"},{"location":"api/#Distributions.logpdf-Tuple{CPD, Dict{Symbol, Any}}","page":"API Documentation","title":"Distributions.logpdf","text":"logpdf(cpd::CPD)\n\nCondition and then return the logpdf\n\n\n\n\n\n","category":"method"},{"location":"api/#Distributions.ncategories-Tuple{CategoricalCPD}","page":"API Documentation","title":"Distributions.ncategories","text":"Distributions.ncategories(cpd::CategoricalCPD)\n\nReturn the number of categories for a cpd.\n\n\n\n\n\n","category":"method"},{"location":"api/#Distributions.pdf-Tuple{CPD, DataFrame}","page":"API Documentation","title":"Distributions.pdf","text":"pdf(cpd::CPD, data::DataFrame)\n\nReturn the pdf across the dataset\n\n\n\n\n\n","category":"method"},{"location":"api/#Distributions.pdf-Tuple{CPD, Dict{Symbol, Any}}","page":"API Documentation","title":"Distributions.pdf","text":"pdf(cpd::CPD)\n\nCondition and then return the pdf\n\n\n\n\n\n","category":"method"},{"location":"api/#StatsAPI.fit-Tuple{Type{CPD}, DataFrame, Symbol, AbstractVector{Symbol}}","page":"API Documentation","title":"StatsAPI.fit","text":"fit(::Type{CPD}, data::DataFrame, target::NodeName, parents::NodeNames)\n\nConstruct a CPD for target by fitting it to the provided data\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.CPDs.@required_func-Tuple{Any}","page":"API Documentation","title":"BayesNets.CPDs.@required_func","text":"required_func(signature)\n\nProvide a default function implementation that throws an error when called.\n\n\n\n\n\n","category":"macro"},{"location":"api/#BayesNets.CPDs.ProbabilisticGraphicalModels","page":"API Documentation","title":"BayesNets.CPDs.ProbabilisticGraphicalModels","text":"Provides a basic interface for defining and working with probabilistic graphical models\n\n\n\n\n\n","category":"module"},{"location":"api/#BayesNets.CPDs.ProbabilisticGraphicalModels.GraphSearchStrategy","page":"API Documentation","title":"BayesNets.CPDs.ProbabilisticGraphicalModels.GraphSearchStrategy","text":"GraphSearchStrategy\n\nAn abstract type which defines a graph search strategy for learning probabilistic graphical model structures These allow: fit(::Type{ProbabilisticGraphicalModel}, data, GraphSearchStrategy)\n\n\n\n\n\n","category":"type"},{"location":"api/#BayesNets.CPDs.ProbabilisticGraphicalModels.InferenceMethod","page":"API Documentation","title":"BayesNets.CPDs.ProbabilisticGraphicalModels.InferenceMethod","text":"Abstract type for probability inference\n\n\n\n\n\n","category":"type"},{"location":"api/#BayesNets.CPDs.ProbabilisticGraphicalModels.InferenceState","page":"API Documentation","title":"BayesNets.CPDs.ProbabilisticGraphicalModels.InferenceState","text":"Type for capturing the inference state\n\n\n\n\n\n","category":"type"},{"location":"api/#BayesNets.CPDs.ProbabilisticGraphicalModels.Sampler","page":"API Documentation","title":"BayesNets.CPDs.ProbabilisticGraphicalModels.Sampler","text":"Abstract type for sampling with Base.rand(ProbabilisticGraphicalModel, Sampler, nsamples)                                 Base.rand!(Assignment, ProbabilisticGraphicalModel, Sampler)                                 Base.rand(ProbabilisticGraphicalModel, Sampler)\n\n\n\n\n\n","category":"type"},{"location":"api/#Base.length-Tuple{ProbabilisticGraphicalModel}","page":"API Documentation","title":"Base.length","text":"length(PGM)\n\nReturns the number of variables in the probabilistic graphical model\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.names-Tuple{ProbabilisticGraphicalModel}","page":"API Documentation","title":"Base.names","text":"names(PGM)\n\nReturns a list of NodeNames\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.rand-Tuple{ProbabilisticGraphicalModel, Sampler, Integer}","page":"API Documentation","title":"Base.rand","text":"Generates a DataFrame containing a dataset of variable assignments. Always return a DataFrame with nsamples rows.\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.rand-Tuple{ProbabilisticGraphicalModel, Sampler}","page":"API Documentation","title":"Base.rand","text":"Returns a new Assignment sampled from the PGM using the provided sampler\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.CPDs.ProbabilisticGraphicalModels.consistent-Tuple{Dict{Symbol, Any}, Dict{Symbol, Any}}","page":"API Documentation","title":"BayesNets.CPDs.ProbabilisticGraphicalModels.consistent","text":"consistent(a::Assignment, b::Assignment)\n\nTrue if all shared NodeNames have the same value\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.CPDs.ProbabilisticGraphicalModels.infer-Tuple{InferenceMethod, InferenceState}","page":"API Documentation","title":"BayesNets.CPDs.ProbabilisticGraphicalModels.infer","text":"infer(InferenceMethod, InferenceState)\n\nInfer p(query|evidence)\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.CPDs.ProbabilisticGraphicalModels.is_independent-Tuple{ProbabilisticGraphicalModel, AbstractVector{Symbol}, AbstractVector{Symbol}, AbstractVector{Symbol}}","page":"API Documentation","title":"BayesNets.CPDs.ProbabilisticGraphicalModels.is_independent","text":"is_independent(PGM, x::NodeNames, y::NodeNames, given::NodeNames) Returns whether the set of node names x is d-separated from the set y given the set given\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.CPDs.ProbabilisticGraphicalModels.markov_blanket-Tuple{ProbabilisticGraphicalModel}","page":"API Documentation","title":"BayesNets.CPDs.ProbabilisticGraphicalModels.markov_blanket","text":"markov_blanket(PGM) Returns the list of NodeNames forming the Markov blanket for the PGM\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesNets.CPDs.ProbabilisticGraphicalModels.nodenames-Tuple{Dict{Symbol, Any}}","page":"API Documentation","title":"BayesNets.CPDs.ProbabilisticGraphicalModels.nodenames","text":"nodenames(a::Assignment)\n\nReturn a vector of NodeNames (aka symbols) for the assignment\n\n\n\n\n\n","category":"method"},{"location":"api/#Distributions.logpdf-Tuple{ProbabilisticGraphicalModel, DataFrame}","page":"API Documentation","title":"Distributions.logpdf","text":"The logpdf of a set of assignment after conditioning on the values\n\n\n\n\n\n","category":"method"},{"location":"api/#Distributions.logpdf-Tuple{ProbabilisticGraphicalModel, Dict{Symbol, Any}}","page":"API Documentation","title":"Distributions.logpdf","text":"The logpdf of a given assignment after conditioning on the values\n\n\n\n\n\n","category":"method"},{"location":"api/#Distributions.pdf-Tuple{ProbabilisticGraphicalModel, DataFrame}","page":"API Documentation","title":"Distributions.pdf","text":"The pdf of a set of assignments after conditioning on the values\n\n\n\n\n\n","category":"method"},{"location":"api/#Distributions.pdf-Tuple{ProbabilisticGraphicalModel, Dict{Symbol, Any}}","page":"API Documentation","title":"Distributions.pdf","text":"The pdf of a given assignment after conditioning on the values\n\n\n\n\n\n","category":"method"},{"location":"api/#Random.rand!-Tuple{Dict{Symbol, Any}, ProbabilisticGraphicalModel, Sampler}","page":"API Documentation","title":"Random.rand!","text":"Overwrites Assignment with a sample from the PGM using the given Sampler\n\n\n\n\n\n","category":"method"},{"location":"api/#StatsAPI.fit-Union{Tuple{P}, Tuple{Type{P}, DataFrame, GraphSearchStrategy}} where P<:ProbabilisticGraphicalModel","page":"API Documentation","title":"StatsAPI.fit","text":"fit(::Type{ProbabilisticGraphicalModel}, data::DataFrame, params::GraphSearchStrategy)\n\nRuns the graph search algorithm to learn a probabilistic graphical model of the provided type from data.\n\n\n\n\n\n","category":"method"},{"location":"api/#Tables.AbstractColumns","page":"API Documentation","title":"Tables.AbstractColumns","text":"Tables.AbstractColumns\n\nAn interface type defined as an ordered set of columns that support retrieval of individual columns by name or index. A retrieved column must be a 1-based indexable collection with known length, i.e. an object that supports length(col) and col[i] for any i = 1:length(col). Tables.columns must return an object that satisfies the Tables.AbstractColumns interface. While Tables.AbstractColumns is an abstract type that custom \"columns\" types may subtype for useful default behavior (indexing, iteration, property-access, etc.), users should not use it for dispatch, as Tables.jl interface objects are not required to subtype, but only implement the required interface methods.\n\nInterface definition:\n\nRequired Methods Default Definition Brief Description\nTables.getcolumn(table, i::Int) getfield(table, i) Retrieve a column by index\nTables.getcolumn(table, nm::Symbol) getproperty(table, nm) Retrieve a column by name\nTables.columnnames(table) propertynames(table) Return column names for a table as a 1-based indexable collection\nOptional methods  \nTables.getcolumn(table, ::Type{T}, i::Int, nm::Symbol) Tables.getcolumn(table, nm) Given a column eltype T, index i, and column name nm, retrieve the column. Provides a type-stable or even constant-prop-able mechanism for efficiency.\n\nNote that subtypes of Tables.AbstractColumns must overload all required methods listed above instead of relying on these methods' default definitions.\n\nWhile types aren't required to subtype Tables.AbstractColumns, benefits of doing so include:\n\nIndexing interface defined (using getcolumn); i.e. tbl[i] will retrieve the column at index i\nProperty access interface defined (using columnnames and getcolumn); i.e. tbl.col1 will retrieve column named col1\nIteration interface defined; i.e. for col in table will iterate each column in the table\nAbstractDict methods defined (get, haskey, etc.) for checking and retrieving columns\nA default show method\n\nThis allows a custom table type to behave as close as possible to a builtin NamedTuple of vectors object.\n\n\n\n\n\n","category":"type"},{"location":"api/#Tables.AbstractRow","page":"API Documentation","title":"Tables.AbstractRow","text":"Tables.AbstractRow\n\nAbstract interface type representing the expected eltype of the iterator returned from Tables.rows(table). Tables.rows must return an iterator of elements that satisfy the Tables.AbstractRow interface. While Tables.AbstractRow is an abstract type that custom \"row\" types may subtype for useful default behavior (indexing, iteration, property-access, etc.), users should not use it for dispatch, as Tables.jl interface objects are not required to subtype, but only implement the required interface methods.\n\nInterface definition:\n\nRequired Methods Default Definition Brief Description\nTables.getcolumn(row, i::Int) getfield(row, i) Retrieve a column value by index\nTables.getcolumn(row, nm::Symbol) getproperty(row, nm) Retrieve a column value by name\nTables.columnnames(row) propertynames(row) Return column names for a row as a 1-based indexable collection\nOptional methods  \nTables.getcolumn(row, ::Type{T}, i::Int, nm::Symbol) Tables.getcolumn(row, nm) Given a column element type T, index i, and column name nm, retrieve the column value. Provides a type-stable or even constant-prop-able mechanism for efficiency.\n\nNote that subtypes of Tables.AbstractRow must overload all required methods listed above instead of relying on these methods' default definitions.\n\nWhile custom row types aren't required to subtype Tables.AbstractRow, benefits of doing so include:\n\nIndexing interface defined (using getcolumn); i.e. row[i] will return the column value at index i\nProperty access interface defined (using columnnames and getcolumn); i.e. row.col1 will retrieve the value for the column named col1\nIteration interface defined; i.e. for x in row will iterate each column value in the row\nAbstractDict methods defined (get, haskey, etc.) for checking and retrieving column values\nA default show method\n\nThis allows the custom row type to behave as close as possible to a builtin NamedTuple object.\n\n\n\n\n\n","category":"type"},{"location":"api/#Tables.ByRow","page":"API Documentation","title":"Tables.ByRow","text":"ByRow <: Function\n\nByRow(f) returns a function which applies function f to each element in a vector.\n\nByRow(f) can be passed two types of arguments:\n\nOne or more 1-based AbstractVectors of equal length: In this case the returned value\n\nis a vector resulting from applying f to elements of passed vectors element-wise. Function f is called exactly once for each element of passed vectors (as opposed to map which assumes for some types of source vectors (e.g. SparseVector) that the wrapped function is pure, and may call the function f only once for multiple equal values.\n\nA Tables.ColumnTable holding 1-based columns of equal length: In this case the function\n\nf is passed a NamedTuple created for each row of passed table.\n\nThe return value of ByRow(f) is always a vector.\n\nByRow expects that at least one argument is passed to it and in the case of Tables.ColumnTable passed that the table has at least one column. In some contexts of operations on tables (for example DataFrame) the user might want to pass no arguments (or an empty Tables.ColumnTable) to ByRow. This case must be separately handled by the code implementing the logic of processing the ByRow operation on this specific parent table (the reason is that passing such arguments to ByRow does not allow it to determine the number of rows of the source table).\n\nExamples\n\njulia> Tables.ByRow(x -> x^2)(1:3)\n3-element Vector{Int64}:\n 1\n 4\n 9\n\njulia> Tables.ByRow((x, y) -> x*y)(1:3, 2:4)\n3-element Vector{Int64}:\n  2\n  6\n 12\n\njulia> Tables.ByRow(x -> x.a)((a=1:2, b=3:4))\n2-element Vector{Int64}:\n 1\n 2\n\n julia> Tables.ByRow(x -> (a=x.a*2, b=sin(x.b), c=x.c))((a=[1, 2, 3],\n                                                         b=[1.2, 3.4, 5.6],\n                                                         c=[\"a\", \"b\", \"c\"]))\n3-element Vector{NamedTuple{(:a, :b, :c), Tuple{Int64, Float64, String}}}:\n (a = 2, b = 0.9320390859672263, c = \"a\")\n (a = 4, b = -0.2555411020268312, c = \"b\")\n (a = 6, b = -0.6312666378723216, c = \"c\")\n\n\n\n\n\n\n","category":"type"},{"location":"api/#Tables.Columns","page":"API Documentation","title":"Tables.Columns","text":"Tables.Columns(tbl)\n\nConvenience type that calls Tables.columns on an input tbl and wraps the resulting AbstractColumns interface object in a dedicated struct to provide useful default behaviors (allows any AbstractColumns to be used like a NamedTuple of Vectors):\n\nIndexing interface defined; i.e. row[i] will return the column at index i, row[nm] will return column for column name nm\nProperty access interface defined; i.e. row.col1 will retrieve the value for the column named col1\nIteration interface defined; i.e. for x in row will iterate each column in the row\nAbstractDict methods defined (get, haskey, etc.) for checking and retrieving columns\n\nNote that Tables.Columns calls Tables.columns internally on the provided table argument. Tables.Columns can be used for dispatch if needed.\n\n\n\n\n\n","category":"type"},{"location":"api/#Tables.CopiedColumns","page":"API Documentation","title":"Tables.CopiedColumns","text":"Tables.CopiedColumns\n\nFor some sinks, there's a concern about whether they can safely \"own\" columns from the input. If mutation will be allowed, to be safe, they should always copy input columns, to avoid unintended mutation to the original source. When we've called buildcolumns, however, Tables.jl essentially built/owns the columns, and it's happy to pass ownership to the sink. Thus, any built columns will be wrapped in a CopiedColumns struct to signal to the sink that essentially \"a copy has already been made\" and they're safe to assume ownership.\n\n\n\n\n\n","category":"type"},{"location":"api/#Tables.LazyTable","page":"API Documentation","title":"Tables.LazyTable","text":"Tables.LazyTable(f, arg)\n\nA \"table\" type that delays materialization until Tables.columns or Tables.rows is called. This allows, for example, sending a LazyTable to a remote process or thread which can then call Tables.columns or Tables.rows to \"materialize\" the table. Is used by default in Tables.partitioner(f, itr) where a materializer function f is passed to each element of an iterable itr, allowing distributed/concurrent patterns like:\n\nfor tbl in Tables.partitions(Tables.partitioner(CSV.File, list_of_csv_files))\n    Threads.@spawn begin\n        cols = Tables.columns(tbl)\n        # do stuff with cols\n    end\nend\n\nIn this example, CSV.File will be called like CSV.File(x) for each element of the list_of_csv_files iterable, but not until Tables.columns(tbl) is called, which in this case happens in a thread-spawned task, allowing files to be parsed and processed in parallel.\n\n\n\n\n\n","category":"type"},{"location":"api/#Tables.Row","page":"API Documentation","title":"Tables.Row","text":"Tables.Row(row)\n\nConvenience type to wrap any AbstractRow interface object in a dedicated struct to provide useful default behaviors (allows any AbstractRow to be used like a NamedTuple):\n\nIndexing interface defined; i.e. row[i] will return the column value at index i, row[nm] will return column value for column name nm\nProperty access interface defined; i.e. row.col1 will retrieve the value for the column named col1\nIteration interface defined; i.e. for x in row will iterate each column value in the row\nAbstractDict methods defined (get, haskey, etc.) for checking and retrieving column values\n\n\n\n\n\n","category":"type"},{"location":"api/#Tables.Schema","page":"API Documentation","title":"Tables.Schema","text":"Tables.Schema(names, types)\n\nCreate a Tables.Schema object that holds the column names and types for an AbstractRow iterator returned from Tables.rows or an AbstractColumns object returned from Tables.columns. Tables.Schema is dual-purposed: provide an easy interface for users to query these properties, as well as provide a convenient \"structural\" type for code generation.\n\nTo get a table's schema, one can call Tables.schema on the result of Tables.rows or Tables.columns, but also note that a table may return nothing, indicating that its column names and/or column element types are unknown (usually not inferable). This is similar to the Base.EltypeUnknown() trait for iterators when Base.IteratorEltype is called. Users should account for the Tables.schema(tbl) => nothing case by using the properties of the results of Tables.rows(x) and Tables.columns(x) directly.\n\nTo access the names, one can simply call sch.names to return a collection of Symbols (Tuple or Vector). To access column element types, one can similarly call sch.types, which will return a collection of types (like (Int64, Float64, String)).\n\nThe actual type definition is\n\nstruct Schema{names, types}\n    storednames::Union{Nothing, Vector{Symbol}}\n    storedtypes::Union{Nothing, Vector{Type}}\nend\n\nWhere names is a tuple of Symbols or nothing, and types is a tuple type of types (like Tuple{Int64, Float64, String}) or nothing. Encoding the names & types as type parameters allows convenient use of the type in generated functions and other optimization use-cases, but users should note that when names and/or types are the nothing value, the names and/or types are stored in the storednames and storedtypes fields. This is to account for extremely wide tables with columns in the 10s of thousands where encoding the names/types as type parameters becomes prohibitive to the compiler. So while optimizations can be written on the typed names/types type parameters, users should also consider handling the extremely wide tables by specializing on Tables.Schema{nothing, nothing}.\n\n\n\n\n\n","category":"type"},{"location":"api/#Tables.allocatecolumn-Tuple{Any, Any}","page":"API Documentation","title":"Tables.allocatecolumn","text":"Tables.allocatecolumn(::Type{T}, len) => returns a column type (usually `AbstractVector`) with size to hold `len` elements\n\nCustom column types can override with an appropriate \"scalar\" element type that should dispatch to their column allocator. Alternatively, and more generally, custom scalars can overload DataAPI.defaultarray to signal the default array type. In this case the signaled array type must support a constructor accepting undef for initialization.\n\n\n\n\n\n","category":"method"},{"location":"api/#Tables.columnaccess","page":"API Documentation","title":"Tables.columnaccess","text":"Tables.columnaccess(x) => Bool\n\nCheck whether an object has specifically defined that it implements the Tables.columns function that does not copy table data.  That is to say, Tables.columns(x) must be done with O(1) time and space complexity when Tables.columnaccess(x) == true.  Note that Tables.columns has generic fallbacks allowing it to produces AbstractColumns objects, even if the input doesn't define columnaccess.  However, this generic fallback may copy the data from input table x.  Also note that just because an object defines columnaccess doesn't mean a user should call Tables.columns on it; Tables.rows will also work, providing a valid AbstractRow iterator. Hence, users should call Tables.rows or Tables.columns depending on what is most natural for them to consume instead of worrying about what and how the input is oriented.\n\nIt is recommended that for users implementing MyType, they define only columnaccess(::Type{MyType}). columnaccess(::MyType) will then automatically delegate to this method.\n\n\n\n\n\n","category":"function"},{"location":"api/#Tables.columnindex-Tuple{Any, Symbol}","page":"API Documentation","title":"Tables.columnindex","text":"Tables.columnindex(table, name::Symbol)\n\nReturn the column index (1-based) of a column by name in a table with a known schema; returns 0 if name doesn't exist in table\n\n\n\n\n\n","category":"method"},{"location":"api/#Tables.columnindex-Tuple{Tuple{Vararg{Symbol}}, Symbol}","page":"API Documentation","title":"Tables.columnindex","text":"given names and a Symbol name, compute the index (1-based) of the name in names\n\n\n\n\n\n","category":"method"},{"location":"api/#Tables.columnnames","page":"API Documentation","title":"Tables.columnnames","text":"Tables.columnnames(::Union{AbstractColumns, AbstractRow}) => Indexable collection\n\nRetrieves the list of column names as a 1-based indexable collection (like a Tuple or Vector) for a AbstractColumns or AbstractRow interface object. The default definition calls propertynames(x). The returned column names must be unique.\n\n\n\n\n\n","category":"function"},{"location":"api/#Tables.columns","page":"API Documentation","title":"Tables.columns","text":"Tables.columns(x) => AbstractColumns-compatible object\n\nAccesses data of input table source x by returning an AbstractColumns-compatible object, which allows retrieving entire columns by name or index. A retrieved column is a 1-based indexable object that has a known length, i.e. supports length(col) and col[i] for any i = 1:length(col). Note that even if the input table source is row-oriented by nature, an efficient generic definition of Tables.columns is defined in Tables.jl to build a AbstractColumns- compatible object object from the input rows.\n\nThe Tables.Schema of a AbstractColumns object can be queried via Tables.schema(columns), which may return nothing if the schema is unknown. Column names can always be queried by calling Tables.columnnames(columns), and individual columns can be accessed by calling Tables.getcolumn(columns, i::Int ) or Tables.getcolumn(columns, nm::Symbol) with a column index or name, respectively.\n\nNote that if x is an object in which columns are stored as vectors, the check that these vectors use 1-based indexing is not performed (it should be ensured when x is constructed).\n\n\n\n\n\n","category":"function"},{"location":"api/#Tables.columntable","page":"API Documentation","title":"Tables.columntable","text":"Tables.columntable(x) => NamedTuple of AbstractVectors\n\nTakes any input table source x and returns a NamedTuple of AbstractVectors, also known as a \"column table\". A \"column table\" is a kind of default table type of sorts, since it satisfies the Tables.jl column interface naturally.\n\nNote that if x is an object in which columns are stored as vectors, the check that these vectors use 1-based indexing is not performed (it should be ensured when x is constructed).\n\nNot for use with extremely wide tables with # of columns > 67K; current fundamental compiler limits prevent constructing NamedTuples that large.\n\n\n\n\n\n","category":"function"},{"location":"api/#Tables.columntype-Tuple{Any, Symbol}","page":"API Documentation","title":"Tables.columntype","text":"Tables.columntype(table, name::Symbol)\n\nReturn the column element type of a column by name in a table with a known schema; returns Union{} if name doesn't exist in table\n\n\n\n\n\n","category":"method"},{"location":"api/#Tables.columntype-Union{Tuple{types}, Tuple{Tuple{Vararg{Symbol}}, Type{types}, Symbol}} where types<:Tuple","page":"API Documentation","title":"Tables.columntype","text":"given tuple type and a Symbol name, compute the type of the name in the tuples types\n\n\n\n\n\n","category":"method"},{"location":"api/#Tables.datavaluerows-Tuple{Any}","page":"API Documentation","title":"Tables.datavaluerows","text":"Tables.datavaluerows(x) => NamedTuple iterator\n\nTakes any table input x and returns a NamedTuple iterator that will replace missing values with DataValue-wrapped values; this allows any table type to satisfy the TableTraits.jl  Queryverse integration interface by defining: \n\nIteratorInterfaceExtensions.getiterator(x::MyTable) = Tables.datavaluerows(x)\n\n\n\n\n\n","category":"method"},{"location":"api/#Tables.dictcolumntable-Tuple{Any}","page":"API Documentation","title":"Tables.dictcolumntable","text":"Tables.dictcolumntable(x) => Tables.DictColumnTable\n\nTake any Tables.jl-compatible source x and return a DictColumnTable, which can be thought of as a OrderedDict mapping column names as Symbols to AbstractVectors. The order of the input table columns is preserved via the Tables.schema(::DictColumnTable).\n\nFor \"schema-less\" input tables, dictcolumntable employs a \"column unioning\" behavior, as opposed to inferring the schema from the first row like Tables.columns. This means that as rows are iterated, each value from the row is joined into an aggregate final set of columns. This is especially useful when input table rows may not include columns if the value is missing, instead of including an actual value missing, which is common in json, for example. This results in a performance cost tracking all seen values and inferring the final unioned schemas, so it's recommended to use only when needed.\n\n\n\n\n\n","category":"method"},{"location":"api/#Tables.dictrowtable-Tuple{Any}","page":"API Documentation","title":"Tables.dictrowtable","text":"Tables.dictrowtable(x) => Tables.DictRowTable\n\nTake any Tables.jl-compatible source x and return a DictRowTable, which can be thought of as a Vector of OrderedDict rows mapping column names as Symbols to values. The order of the input table columns is preserved via the Tables.schema(::DictRowTable).\n\nFor \"schema-less\" input tables, dictrowtable employs a \"column unioning\" behavior, as opposed to inferring the schema from the first row like Tables.columns. This means that as rows are iterated, each value from the row is joined into an aggregate final set of columns. This is especially useful when input table rows may not include columns if the value is missing, instead of including an actual value missing, which is common in json, for example. This results in a performance cost tracking all seen values and inferring the final unioned schemas, so it's recommended to use only when the union behavior is needed.\n\n\n\n\n\n","category":"method"},{"location":"api/#Tables.eachcolumn","page":"API Documentation","title":"Tables.eachcolumn","text":"Tables.eachcolumn(f, sch::Tables.Schema{names, types}, x::Union{Tables.AbstractRow, Tables.AbstractColumns})\nTables.eachcolumn(f, sch::Tables.Schema{names, nothing}, x::Union{Tables.AbstractRow, Tables.AbstractColumns})\n\nTakes a function f, table schema sch, x, which is an object that satisfies the AbstractRow or AbstractColumns interfaces; it generates calls to get the value for each column (Tables.getcolumn(x, nm)) and then calls f(val, index, name), where f is the user-provided function, val is the column value (AbstractRow) or entire column (AbstractColumns), index is the column index as an Int, and name is the column name as a Symbol.\n\nAn example using Tables.eachcolumn is:\n\nrows = Tables.rows(tbl)\nsch = Tables.schema(rows)\nif sch === nothing\n    state = iterate(rows)\n    state === nothing && return\n    row, st = state\n    sch = Tables.schema(Tables.columnnames(row), nothing)\n    while state !== nothing\n        Tables.eachcolumn(sch, row) do val, i, nm\n            bind!(stmt, i, val)\n        end\n        state = iterate(rows, st)\n        state === nothing && return\n        row, st = state\n    end\nelse\n    for row in rows\n        Tables.eachcolumn(sch, row) do val, i, nm\n            bind!(stmt, i, val)\n        end\n    end\nend\n\nNote in this example we account for the input table potentially returning nothing from Tables.schema(rows); in that case, we start iterating the rows, and build a partial schema using the column names from the first row sch = Tables.schema(Tables.columnnames(row), nothing), which is valid to pass to Tables.eachcolumn.\n\n\n\n\n\n","category":"function"},{"location":"api/#Tables.getcolumn","page":"API Documentation","title":"Tables.getcolumn","text":"Tables.getcolumn(::AbstractColumns, nm::Symbol) => Indexable collection with known length\nTables.getcolumn(::AbstractColumns, i::Int) => Indexable collection with known length\nTables.getcolumn(::AbstractColumns, T, i::Int, nm::Symbol) => Indexable collection with known length\n\nTables.getcolumn(::AbstractRow, nm::Symbol) => Column value\nTables.getcolumn(::AbstractRow, i::Int) => Column value\nTables.getcolumn(::AbstractRow, T, i::Int, nm::Symbol) => Column value\n\nRetrieve an entire column (from AbstractColumns) or single row column value (from an AbstractRow) by column name (nm), index (i), or if desired, by column element type (T), index (i), and name (nm). When called on a AbstractColumns interface object, the returned object should be a 1-based indexable collection with known length. When called on a AbstractRow interface object, it returns the single column value. The methods taking a single Symbol or Int are both required for the AbstractColumns and AbstractRow interfaces; the third method is optional if type stability is possible. The default definition of Tables.getcolumn(x, i::Int) is getfield(x, i). The default definition of Tables.getcolumn(x, nm::Symbol) is getproperty(x, nm).\n\n\n\n\n\n","category":"function"},{"location":"api/#Tables.isrowtable","page":"API Documentation","title":"Tables.isrowtable","text":"Tables.isrowtable(x) => Bool\n\nFor convenience, some table objects that are naturally \"row oriented\" can define Tables.isrowtable(::Type{TableType}) = true to simplify satisfying the Tables.jl interface. Requirements for defining isrowtable include:\n\nTables.rows(x) === x, i.e. the table object itself is a Row iterator\nIf the table object is mutable, it should support:\npush!(x, row): allow pushing a single row onto table\nappend!(x, rows): allow appending set of rows onto table\nIf table object is mutable and indexable, it should support:\nx[i] = row: allow replacing of a row with another row by index\n\nA table object that defines Tables.isrowtable will have definitions for Tables.istable, Tables.rowaccess, and Tables.rows automatically defined.\n\n\n\n\n\n","category":"function"},{"location":"api/#Tables.istable","page":"API Documentation","title":"Tables.istable","text":"Tables.istable(x) => Bool\n\nCheck if an object has specifically defined that it is a table. Note that not all valid tables will return true, since it's possible to satisfy the Tables.jl interface at \"run-time\", e.g. a Generator of NamedTuples iterates NamedTuples, which satisfies the AbstractRow interface, but there's no static way of knowing that the generator is a table.\n\nIt is recommended that for users implementing MyType, they define only istable(::Type{MyType}). istable(::MyType) will then automatically delegate to this method.\n\nistable calls TableTraits.isiterabletable as a fallback. This can have a considerable runtime overhead in some contexts. To avoid these and use istable as a compile-time trait, it can be called on a type as istable(typeof(obj)).\n\n\n\n\n\n","category":"function"},{"location":"api/#Tables.materializer","page":"API Documentation","title":"Tables.materializer","text":"Tables.materializer(x) => Callable\n\nFor a table input, return the \"sink\" function or \"materializing\" function that can take a Tables.jl-compatible table input and make an instance of the table type. This enables \"transform\" workflows that take table inputs, apply transformations, potentially converting the table to a different form, and end with producing a table of the same type as the original input. The default materializer is Tables.columntable, which converts any table input into a NamedTuple of Vectors.\n\nIt is recommended that for users implementing MyType, they define only materializer(::Type{<:MyType}). materializer(::MyType) will then automatically delegate to this method.\n\n\n\n\n\n","category":"function"},{"location":"api/#Tables.matrix-Tuple{Any}","page":"API Documentation","title":"Tables.matrix","text":"Tables.matrix(table; transpose::Bool=false)\n\nMaterialize any table source input as a new Matrix or in the case of a MatrixTable return the originally wrapped matrix. If the table column element types are not homogeneous, they will be promoted to a common type in the materialized Matrix. Note that column names are ignored in the conversion. By default, input table columns will be materialized as corresponding matrix columns; passing transpose=true will transpose the input with input columns as matrix rows or in the case of a MatrixTable apply permutedims to the originally wrapped matrix.\n\n\n\n\n\n","category":"method"},{"location":"api/#Tables.namedtupleiterator-Tuple{Any}","page":"API Documentation","title":"Tables.namedtupleiterator","text":"Tables.namedtupleiterator(x)\n\nPass any table input source and return a NamedTuple iterator\n\nSee also rows and rowtable.\n\nNot for use with extremely wide tables with # of columns > 67K; current fundamental compiler limits prevent constructing NamedTuples that large.\n\n\n\n\n\n","category":"method"},{"location":"api/#Tables.nondatavaluerows-Tuple{Any}","page":"API Documentation","title":"Tables.nondatavaluerows","text":"Tables.nondatavaluerows(x)\n\nTakes any Queryverse-compatible NamedTuple iterator source and  converts to a Tables.jl-compatible AbstractRow iterator. Will automatically unwrap any DataValues, replacing NA with missing. Useful for translating Query.jl results back to non-DataValue-based tables.\n\n\n\n\n\n","category":"method"},{"location":"api/#Tables.partitioner-Tuple{Any}","page":"API Documentation","title":"Tables.partitioner","text":"Tables.partitioner(f, itr)\nTables.partitioner(x)\n\nConvenience methods to generate table iterators. The first method takes a \"materializer\" function f and an iterator itr, and will call Tables.LazyTable(f, x) for x in itr for each iteration. This allows delaying table materialization until Tables.columns or Tables.rows are called on the LazyTable object (which will call f(x)). This allows a common desired pattern of materializing and processing a table on a remote process or thread, like:\n\nfor tbl in Tables.partitions(Tables.partitioner(CSV.File, list_of_csv_files))\n    Threads.@spawn begin\n        cols = Tables.columns(tbl)\n        # do stuff with cols\n    end\nend\n\nThe second method is provided because the default behavior of Tables.partition(x) is to treat x as a single, non-partitioned table. This method allows users to easily wrap a Vector or generator of tables as table partitions to pass to sink functions able to utilize Tables.partitions.\n\n\n\n\n\n","category":"method"},{"location":"api/#Tables.partitions-Tuple{Any}","page":"API Documentation","title":"Tables.partitions","text":"Tables.partitions(x)\n\nRequest a \"table\" iterator from x. Each iterated element must be a \"table\" in the sense that one may call Tables.rows or Tables.columns to get a row-iterator or collection of columns. All iterated elements must have identical schema, so that users may call Tables.schema(first_element) on the first iterated element and know that each subsequent iteration will match the same schema. The default definition is:\n\nTables.partitions(x) = (x,)\n\nSo that any input is assumed to be a single \"table\". This means users should feel free to call Tables.partitions anywhere they're currently calling Tables.columns or Tables.rows, and get back an iterator of those instead. In other words, \"sink\" functions can use Tables.partitions whether or not the user passes a partionable table, since the default is to treat a single input as a single, non-partitioned table.\n\nTables.partitioner(itr) is a convenience wrapper to provide table partitions from any table iterator; this allows for easy wrapping of a Vector or iterator of tables as valid partitions, since by default, they'd be treated as a single table.\n\nA 2nd convenience method is provided with the definition:\n\nTables.partitions(x...) = x\n\nThat allows passing vararg tables and they'll be treated as separate partitions. Sink functions may allow vararg table inputs and can \"splat them through\" to partitions.\n\nFor convenience, Tables.partitions(x::Iterators.PartitionIterator) = x and Tables.partitions(x::Tables.Partitioner) = x are defined to handle cases where user created partitioning with the Iterators.partition or Tables.partitioner functions.\n\n\n\n\n\n","category":"method"},{"location":"api/#Tables.rowaccess","page":"API Documentation","title":"Tables.rowaccess","text":"Tables.rowaccess(x) => Bool\n\nCheck whether an object has specifically defined that it implements the Tables.rows function that does not copy table data.  That is to say, Tables.rows(x) must be done with O(1) time and space complexity when Tables.rowaccess(x) == true.  Note that Tables.rows will work on any object that iterates AbstractRow-compatible objects, even if they don't define rowaccess, e.g. a Generator of NamedTuples.  However, this generic fallback may copy the data from input table x.  Also note that just because an object defines rowaccess doesn't mean a user should call Tables.rows on it; Tables.columns will also work, providing a valid AbstractColumns object from the rows. Hence, users should call Tables.rows or Tables.columns depending on what is most natural for them to consume instead of worrying about what and how the input is oriented.\n\nIt is recommended that for users implementing MyType, they define only rowaccess(::Type{MyType}). rowaccess(::MyType) will then automatically delegate to this method.\n\n\n\n\n\n","category":"function"},{"location":"api/#Tables.rowmerge-Tuple{Any, Any}","page":"API Documentation","title":"Tables.rowmerge","text":"rowmerge(row, other_rows...)\nrowmerge(row; fields_to_merge...)\n\nReturn a NamedTuple by merging row (an AbstractRow-compliant value) with other_rows (one or more AbstractRow-compliant values) via Base.merge. This function is similar to Base.merge(::NamedTuple, ::NamedTuple...), but accepts AbstractRow-compliant values instead of NamedTuples.\n\nA convenience method rowmerge(row; fields_to_merge...) = rowmerge(row, fields_to_merge) is defined that enables the fields_to_merge to be specified as keyword arguments.\n\n\n\n\n\n","category":"method"},{"location":"api/#Tables.rows","page":"API Documentation","title":"Tables.rows","text":"Tables.rows(x) => Row iterator\n\nAccesses data of input table source x row-by-row by returning an AbstractRow-compatible iterator. Note that even if the input table source is column-oriented by nature, an efficient generic definition of Tables.rows is defined in Tables.jl to return an iterator of row views into the columns of the input.\n\nThe Tables.Schema of an AbstractRow iterator can be queried via Tables.schema(rows), which may return nothing if the schema is unknown. Column names can always be queried by calling Tables.columnnames(row) on an individual row, and row values can be accessed by calling Tables.getcolumn(row, i::Int ) or Tables.getcolumn(row, nm::Symbol) with a column index or name, respectively.\n\nSee also rowtable and namedtupleiterator.\n\n\n\n\n\n","category":"function"},{"location":"api/#Tables.rowtable","page":"API Documentation","title":"Tables.rowtable","text":"Tables.rowtable(x) => Vector{NamedTuple}\n\nTake any input table source, and produce a Vector of NamedTuples, also known as a \"row table\". A \"row table\" is a kind of default table type of sorts, since it satisfies the Tables.jl row interface naturally, i.e. a Vector naturally iterates its elements, and NamedTuple satisfies the AbstractRow interface by default (allows indexing value by index, name, and getting all names).\n\nFor a lazy iterator over rows see rows and namedtupleiterator.\n\nNot for use with extremely wide tables with # of columns > 67K; current fundamental compiler limits prevent constructing NamedTuples that large.\n\n\n\n\n\n","category":"function"},{"location":"api/#Tables.runlength-Union{Tuple{Type{T}}, Tuple{T}} where T<:Tuple","page":"API Documentation","title":"Tables.runlength","text":"helper function to calculate a run-length encoding of a tuple type\n\n\n\n\n\n","category":"method"},{"location":"api/#Tables.schema","page":"API Documentation","title":"Tables.schema","text":"Tables.schema(x) => Union{Nothing, Tables.Schema}\n\nAttempt to retrieve the schema of the object returned by Tables.rows or Tables.columns. If the AbstractRow iterator or AbstractColumns object can't determine its schema, nothing will be returned. Otherwise, a Tables.Schema object is returned, with the column names and types available for use.\n\n\n\n\n\n","category":"function"},{"location":"api/#Tables.subset-Union{Tuple{T}, Tuple{T, Any}} where T","page":"API Documentation","title":"Tables.subset","text":"Tables.subset(x, inds; viewhint=nothing)\n\nReturn one or more rows from table x according to the position(s) specified by inds:\n\nIf inds is a single non-boolean integer return a row object.\nIf inds is a vector of non-boolean integers, a vector of booleans, or a :, return a subset of the original table according to the indices. In this case, the returned type is not necessarily the same as the original table type.\n\nIf other types of inds are passed than specified above the behavior is undefined.\n\nThe viewhint argument tries to influence whether the returned object is a view of the original table or an independent copy:\n\nIf viewhint=nothing (the default) then the implementation for a specific table type is free to decide  whether to return a copy or a view.\nIf viewhint=true then a view is returned and if viewhint=false a copy is returned. This applies both to returning a row or a table.\n\nAny specialized implementation of subset must support the viewhint=nothing argument. Support for viewhint=true or viewhint=false is optional (i.e. implementations may ignore the keyword argument and return a view or a copy regardless of viewhint value).\n\n\n\n\n\n","category":"method"},{"location":"api/#Tables.table-Tuple{AbstractVecOrMat}","page":"API Documentation","title":"Tables.table","text":"Tables.table(m::AbstractVecOrMat; [header])\n\nWrap an AbstractVecOrMat (Matrix, Vector, Adjoint, etc.) in a MatrixTable, which satisfies the Tables.jl interface.  (An AbstractVector is treated as a 1-column matrix.) This allows accessing the matrix via Tables.rows and Tables.columns. An optional keyword argument iterator header can be passed which will be converted to a Vector{Symbol} to be used as the column names. Note that no copy of the AbstractVecOrMat is made.\n\n\n\n\n\n","category":"method"},{"location":"concepts/#Concepts","page":"Concepts","title":"Concepts","text":"","category":"section"},{"location":"concepts/#Bayesian-Networks","page":"Concepts","title":"Bayesian Networks","text":"","category":"section"},{"location":"concepts/","page":"Concepts","title":"Concepts","text":"A Bayesian Network (BN) represents a probability distribution over a set of variables, P(x_1 x_2 ldots x_n).  Bayesian networks leverage variable relations in order to efficiently decompose the joint distribution into smaller conditional probability distributions.","category":"page"},{"location":"concepts/","page":"Concepts","title":"Concepts","text":"A BN is defined by a directed acyclic graph and a set of conditional probability distributions. Each node in the graph corresponds to a variable x_i and is associated with a conditional probability distribution P(x_i mid textparents(x_i)).","category":"page"},{"location":"usage/#Usage","page":"Usage","title":"Usage","text":"","category":"section"},{"location":"usage/","page":"Usage","title":"Usage","text":"using BayesNets, TikzGraphs, TikzPictures","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"using Random\nRandom.seed!(0) # seed the random number generator to 0, for a reproducible demonstration\nusing BayesNets\nusing TikzGraphs # required to plot tex-formatted graphs (recommended), otherwise GraphPlot.jl is used\nusing TikzPictures","category":"page"},{"location":"usage/#Representation","page":"Usage","title":"Representation","text":"","category":"section"},{"location":"usage/","page":"Usage","title":"Usage","text":"Bayesian Networks are represented with the BayesNet type. This type contains the directed acyclic graph (a LightTables.DiGraph) and a list of conditional probability distributions (a list of CPDs). Here we construct the BayesNet a rightarrow b, with Gaussians a and b:","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"a = mathcalN(01) qquad b = mathcalN(2a +31)","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"bn = BayesNet()\npush!(bn, StaticCPD(:a, Normal(1.0)))\npush!(bn, LinearGaussianCPD(:b, [:a], [2.0], 3.0, 1.0))\nplot = BayesNets.plot(bn)\nTikzPictures.save(SVG(\"plot1\"), plot)","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"(Image: )","category":"page"},{"location":"usage/#Conditional-Probability-Distributions","page":"Usage","title":"Conditional Probability Distributions","text":"","category":"section"},{"location":"usage/","page":"Usage","title":"Usage","text":"Conditional Probability Distributions, P(x_i mid textparents(x_i)), are defined in BayesNets.CPDs. Each CPD knows its own name, the names of its parents, and is associated with a distribution from Distributions.jl.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"CPDForm Description\nStaticCPD Any Distributions.distribution; independent of any parents\nFunctionalCPD Allows for a CPD defined with a custom eval function\nParentFunctionalCPD Modification to FunctionalCPD allowing the parent values to be passed in\nCategoricalCPD Categorical distribution, assumes integer parents in 1N\nLinearGaussianCPD Linear Gaussian, assumes target and parents are numeric\nConditionalLinearGaussianCPD A linear Gaussian for each discrete parent instantiation","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"Each CPD can be learned from data using fit. Here we learn the same network as above.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"a = randn(100)\nb = randn(100) .+ 2*a .+ 3\n\ndata = DataFrame(a=a, b=b)\ncpdA = fit(StaticCPD{Normal}, data, :a)\ncpdB = fit(LinearGaussianCPD, data, :b, [:a])\n\nbn2 = BayesNet([cpdA, cpdB])\nplot = BayesNets.plot(bn2) # hide\nTikzPictures.save(SVG(\"plot2\"), plot) # hide","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"(Image: )","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"Each CPD implements four functions:","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"name(cpd) - obtain the name of the variable target variable\nparents(cpd) - obtain the list of parents\nnparams(cpd - obtain the number of free parameters in the CPD\ncpd(assignment) - allows calling cpd() to obtain the conditional distribution\nDistributions.fit(Type{CPD}, data, target, parents)","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"cpdB(:a=>0.5)","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"Several functions conveniently condition and then produce their return values:","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"rand(cpdB, :a=>0.5) # condition and then sample\npdf(cpdB, :a=>1.0, :b=>3.0) # condition and then compute pdf(distribution, 3)\nlogpdf(cpdB, :a=>1.0, :b=>3.0) # condition and then compute logpdf(distribution, 3);","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"The NamedCategorical distribution allows for String or Symbol return values. The FunctionalCPD allows for crafting quick and simple CPDs:","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"bn2 = BayesNet()\npush!(bn2, StaticCPD(:sighted, NamedCategorical([:bird, :plane, :superman], [0.40, 0.55, 0.05])))\npush!(bn2, FunctionalCPD{Bernoulli}(:happy, [:sighted], a->Bernoulli(a == :superman ? 0.95 : 0.2)))\nplot = BayesNets.plot(bn2) # hide\nTikzPictures.save(SVG(\"plot3\"), plot) # hide","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"(Image: )","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"Variables can be removed by name using delete!. A warning will be issued when removing a CPD with children.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"delete!(bn2, :happy)\nplot = BayesNets.plot(bn2) # hide\nTikzPictures.save(SVG(\"plot4\"), plot) # hide","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"(Image: )","category":"page"},{"location":"usage/#Likelihood","page":"Usage","title":"Likelihood","text":"","category":"section"},{"location":"usage/","page":"Usage","title":"Usage","text":"A Bayesian Network represents a joint probability distribution, P(x_1 x_2 ldots x_n). Assignments are represented as dictionaries mapping variable names (Symbols) to variable values. We can evaluate probabilities as we would with Distributions.jl, only we use exclamation points as we modify the internal state when we condition:","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"pdf(bn, :a=>0.5, :b=>2.0) # evaluate the probability density","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"We can also evaluate the likelihood of a dataset:","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"data = DataFrame(a=[0.5,1.0,2.0], b=[4.0,5.0,7.0])\npdf(bn, data)    #  0.00215\nlogpdf(bn, data) # -6.1386;","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"Or the likelihood for a particular cpd:","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"pdf(cpdB, data)    #  0.006\nlogpdf(cpdB, data) # -5.201","category":"page"},{"location":"usage/#Sampling","page":"Usage","title":"Sampling","text":"","category":"section"},{"location":"usage/","page":"Usage","title":"Usage","text":"Assignments can be sampled from a BayesNet.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"rand(bn)","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"rand(bn, 5)","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"In general, sampling can be done according to rand(BayesNet, BayesNetSampler, nsamples) to produce a table of samples, rand(BayesNet, BayesNetSampler) to produce a single Assignment, or rand!(Assignment, BayesNet, BayesNetSampler) to modify an assignment in-place. New samplers need only implement rand!. The functions above default to the DirectSampler, which samples the variables in topographical order.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"Rejection sampling can be used to draw samples that are consistent with a provided assignment:","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"bn = BayesNet()\npush!(bn, StaticCPD(:a, Categorical([0.3,0.7])))\npush!(bn, StaticCPD(:b, Categorical([0.6,0.4])))\npush!(bn, CategoricalCPD{Bernoulli}(:c, [:a, :b], [2,2], [Bernoulli(0.1), Bernoulli(0.2), Bernoulli(1.0), Bernoulli(0.4)]))\nplot = BayesNets.plot(bn) # hide\nTikzPictures.save(SVG(\"plot5\"), plot) # hide","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"(Image: )","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"rand(bn, RejectionSampler(:c=>1), 5)","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"One can also use weighted sampling:","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"rand(bn, LikelihoodWeightedSampler(:c=>1), 5)","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"One can also use Gibbs sampling. More options are available than are shown in the example below.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"bn_gibbs = BayesNet()\npush!(bn_gibbs, StaticCPD(:a, Categorical([0.999,0.001])))\npush!(bn_gibbs, StaticCPD(:b, Normal(1.0)))\npush!(bn_gibbs, LinearGaussianCPD(:c, [:a, :b], [3.0, 1.0], 0.0, 1.0))\n\nevidence = Assignment(:c => 10.0)\ninitial_sample = Assignment(:a => 1, :b => 1, :c => 10.0)\ngsampler = GibbsSampler(evidence, burn_in=500, thinning=1, initial_sample=initial_sample)\nrand(bn_gibbs, gsampler, 5)","category":"page"},{"location":"usage/#Parameter-Learning","page":"Usage","title":"Parameter Learning","text":"","category":"section"},{"location":"usage/","page":"Usage","title":"Usage","text":"BayesNets.jl supports parameter learning for an entire graph.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"fit(BayesNet, data, (:a=>:b), [StaticCPD{Normal}, LinearGaussianCPD])","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"fit(BayesNet, data, (:a=>:b), LinearGaussianCPD)","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"Fitting can be done for specific BayesNets types as well:","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"data = DataFrame(c=[1,1,1,1,2,2,2,2,3,3,3,3],\nb=[1,1,1,2,2,2,2,1,1,2,1,1],\na=[1,1,1,2,1,1,2,1,1,2,1,1])\n\nbn5 = fit(DiscreteBayesNet, data, (:a=>:b, :a=>:c, :b=>:c))\nplot = BayesNets.plot(bn5) # hide\nTikzPictures.save(SVG(\"plot6\"), plot) # hide","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"(Image: )","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"Fitting a DiscreteCPD, which is a CategoricalCPD{Categorical}, can be done with a specified number of categories. This prevents cases where your test data does not provide an example for every category.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"cpd = fit(DiscreteCPD, DataFrame(a=[1,2,1,2,2]), :a, ncategories=3);\ncpd = fit(DiscreteCPD, data, :b, [:a], parental_ncategories=[3], target_ncategories=3);","category":"page"},{"location":"usage/#Inference","page":"Usage","title":"Inference","text":"","category":"section"},{"location":"usage/","page":"Usage","title":"Usage","text":"Inference methods for discrete Bayesian networks can be used via the infer method:","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"bn = DiscreteBayesNet()\npush!(bn, DiscreteCPD(:a, [0.3,0.7]))\npush!(bn, DiscreteCPD(:b, [0.2,0.8]))\npush!(bn, DiscreteCPD(:c, [:a, :b], [2,2],\n        [Categorical([0.1,0.9]),\n         Categorical([0.2,0.8]),\n         Categorical([1.0,0.0]),\n         Categorical([0.4,0.6]),\n        ]))\n\nplot = BayesNets.plot(bn) # hide\nTikzPictures.save(SVG(\"plot7\"), plot) # hide","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"(Image: )","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"ϕ = infer(bn, :c, evidence=Assignment(:b=>1))","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"Several inference methods are available. Exact inference is the default.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"Inference Method Description\nExactInference Performs exact inference using discrete factors and variable elimination\nLikelihoodWeightingInference Approximates p(query \\ evidence) with N weighted samples using likelihood weighted sampling\nLoopyBelief The loopy belief propagation algorithm\nGibbsSamplingNodewise Gibbs sampling where each iteration changes one node\nGibbsSamplingFull Gibbs sampling where each iteration changes all nodes","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"ϕ = infer(GibbsSamplingNodewise(), bn, [:a, :b], evidence=Assignment(:c=>2))","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"Inference produces a Factor type. It can be converted to a DataFrame.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"convert(DataFrame, ϕ)","category":"page"},{"location":"usage/#Structure-Learning","page":"Usage","title":"Structure Learning","text":"","category":"section"},{"location":"usage/","page":"Usage","title":"Usage","text":"Structure learning can be done as well.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"using Discretizers\nusing RDatasets\niris = dataset(\"datasets\", \"iris\")\nnames(iris)\ndata = DataFrame(\n    SepalLength = iris[!,:SepalLength],\n    SepalWidth = iris[!,:SepalWidth],\n    PetalLength = iris[!,:PetalLength],\n    PetalWidth = iris[!,:PetalWidth],\n    Species = encode(CategoricalDiscretizer(iris[!,:Species]), iris[!,:Species]),\n)\n\ndata[1:3,:] # only display a subset...","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"Here we use the K2 structure learning algorithm which runs in polynomial time but requires that we specify a topological node ordering.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"parameters = K2GraphSearch([:Species, :SepalLength, :SepalWidth, :PetalLength, :PetalWidth],\n                       ConditionalLinearGaussianCPD,\n                       max_n_parents=2)\nbn = fit(BayesNet, data, parameters)\n\nplot = BayesNets.plot(bn) # hide\nTikzPictures.save(SVG(\"plot8\"), plot) # hide","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"(Image: )","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"CPD types can also be specified per-node. Note that complete CPD definitions are required - simply using StaticCPD is insufficient as you need the target distribution type as well, as in StaticCPD{Categorical}.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"Changing the ordering will change the structure.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"CLG = ConditionalLinearGaussianCPD\nparameters = K2GraphSearch([:Species, :PetalLength, :PetalWidth, :SepalLength, :SepalWidth],\n                        [StaticCPD{Categorical}, CLG, CLG, CLG, CLG],\n                        max_n_parents=2)\nfit(BayesNet, data, parameters)","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"A ScoringFunction allows for extracting a scoring metric for a CPD given data. The negative BIC score is implemented in NegativeBayesianInformationCriterion.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"A GraphSearchStrategy defines a structure learning algorithm. The K2 algorithm is defined through K2GraphSearch and GreedyHillClimbing is implemented for discrete Bayesian networks and the Bayesian score:","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"data = DataFrame(c=[1,1,1,1,2,2,2,2,3,3,3,3],\n                 b=[1,1,1,2,2,2,2,1,1,2,1,1],\n                 a=[1,1,1,2,1,1,2,1,1,2,1,1])\nparameters = GreedyHillClimbing(ScoreComponentCache(data), max_n_parents=3, prior=UniformPrior())\nbn = fit(DiscreteBayesNet, data, parameters)\n\nplot = BayesNets.plot(bn) # hide\nTikzPictures.save(SVG(\"plot9\"), plot) # hide","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"(Image: )","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"We can specify the number of categories for each variable in case it cannot be correctly inferred:","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"bn = fit(DiscreteBayesNet, data, parameters, ncategories=[3,3,2])","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"A whole suite of features are supported for DiscreteBayesNets. Here, we illustrate the following:","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"Obtain a list of counts for a node\nObtain sufficient statistics from a discrete dataset\nObtain the factor table for a node\nObtain a factor table matching a particular assignment","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"We also detail obtaining a Bayesian score for a network structure in the next section.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"count(bn, :a, data)","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"statistics(bn.dag, data)","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"table(bn, :b)","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"table(bn, :c, :a=>1)","category":"page"},{"location":"usage/#Reading-from-XDSL","page":"Usage","title":"Reading from XDSL","text":"","category":"section"},{"location":"usage/","page":"Usage","title":"Usage","text":"Discrete Bayesian Networks can be read from the .XDSL file format.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"bn = readxdsl(joinpath(dirname(pathof(BayesNets)), \"..\", \"test\", \"sample_bn.xdsl\"))\n\nplot = BayesNets.plot(bn) # hide\nTikzPictures.save(SVG(\"plot10\"), plot) # hide","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"(Image: )","category":"page"},{"location":"usage/#Bayesian-Score-for-a-Network-Structure","page":"Usage","title":"Bayesian Score for a Network Structure","text":"","category":"section"},{"location":"usage/","page":"Usage","title":"Usage","text":"The Bayesian score for a discrete-valued BayesNet can be calculated based only on the structure and data (the CPDs do not need to be defined beforehand). This is implemented with a method of bayesian_score that takes in a directed graph, the names of the nodes and data.","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"data = DataFrame(c=[1,1,1,1,2,2,2,2,3,3,3,3],\n                 b=[1,1,1,2,2,2,2,1,1,2,1,1],\n                 a=[1,1,1,2,1,1,2,1,1,2,1,1])\ng = DAG(3)\nadd_edge!(g,1,2); add_edge!(g,2,3); add_edge!(g,1,3)\nbayesian_score(g, [:a,:b,:c], data)","category":"page"},{"location":"install/#Installation","page":"Installation","title":"Installation","text":"","category":"section"},{"location":"install/","page":"Installation","title":"Installation","text":"Pkg.add(\"BayesNets\");","category":"page"},{"location":"install/","page":"Installation","title":"Installation","text":"Default visualization of the network structure is provided by the GraphPlot package. However, we recommend using tex-formatted graphs provided by the TikzGraphs package. Installation requirements for TikzGraphs (e.g., PGF/Tikz and pdf2svg) are provided here. Simply run using TikzGraphs in your Julia session to automatically switch to tex-formatted graphs (thanks to the Requires.jl package).","category":"page"},{"location":"#[BayesNets](https://github.com/sisl/BayesNets.jl)","page":"BayesNets","title":"BayesNets","text":"","category":"section"},{"location":"","page":"BayesNets","title":"BayesNets","text":"A Julia package for Bayesian Networks","category":"page"},{"location":"#Table-of-Contents","page":"BayesNets","title":"Table of Contents","text":"","category":"section"},{"location":"","page":"BayesNets","title":"BayesNets","text":"Pages = Main.page_order","category":"page"}]
}
